---
title: "Estimating the number of COVID-19 cases from population isolation level"
author: "Adriano J. Holanda"
output: html_notebook
---

# Preface

All variables and functions have the prefix `pandiso` in the name. 

# System

The system variables and functions handle the current directory 
value, the manuscript directory and the image format. A function 
is offered to write the files in the right location and the preprint
directory (images and macros) is modified only 
if `pandiso.update.preprint` is assigned to `TRUE`.


```{r}
library(testit) # assert
# Control verbosity
VERBOSE = FALSE
# SYSTEM variables and functions
## Directory where the manuscript (preprint) is located
pandiso.preprint.dir <- "preprint"

## File extension for plots
pandiso.plot.ext <- ".png"

pandiso.file.path <- function(fn) {
  # getwd() returns the current working directory.
  fp <- file.path(getwd(), fn);
  return(fp)
}

# Assign TRUE to update files in the preprint directory
pandiso.update.preprint <- TRUE

pandiso.write.plot <- function(file_prefix, plt) {
  assert("1st parameter is file prefix string", 
         typeof(file_prefix) == "character")
  
  fn <- file.path(pandiso.preprint.dir, 
                  paste(file_prefix, pandiso.plot.ext, sep = ""))
  fp <- pandiso.file.path(fn)
  
  if (pandiso.update.preprint == FALSE) {
    if (VERBOSE) {
      print(paste("* Didn't write", fp))
      print("* Assign 'TRUE' to variable 'pandiso.update.preprint.plots' to write it.")
    
    }
    return(pandiso.update.preprint)
  }
  
  ggsave(fp)
  if (VERBOSE) {
    print(paste("* Wrote", fp))
  }
  return(pandiso.update.preprint)
}
```

## Macros

The values used in the manuscript are assigned to $\TeX$ macros in a file 
in the `preprint` directory. 

```{r}
pandiso.write.TeX_macros <- function() {
  if (pandiso.update.preprint == FALSE)
    return(pandiso.update.preprint)
  
  fp <- file.path(getwd(), pandiso.preprint.dir, "macros.tex")
  tex <- "% This file is automatically generated by R. %\n"
  tex <- paste(tex, "\\usepackage{tikz}\n", sep = "")
  tex <- paste(tex,"\\def\\pandisofitK{", 
               format(pandiso.fit.K, big.mark = ",", digits = 7, nsmall = 0), 
               "}%\n", sep = "")
  tex <- paste(tex,"\\def\\pandisofitm{", 
               format(pandiso.fit.m, big.mark = ",", digits=6, nsmall = 0),
               "}%", sep = "")
  tex <- paste(tex, "\n\\pgfkeys{%\n", sep = "")
  tex <- paste(tex,"\t/pandiso/count/time/steps/.initial=", 
               format(pandiso.count.time.steps, digits=3, nsmall = 0),
               ",%\n", sep = "")
  tex <- paste(tex, "\t/pandiso/date/first/.initial=", pandiso.date.first, ",%\n", sep = "")
  tex <- paste(tex,"\t/pandiso/date/last/.initial=", pandiso.date.last, ",%\n", sep = "")
  tex <- paste(tex,"\t/pandiso/estimation/pearson/.initial=", 
               format(pandiso.estimation.pearson, digits = 1, nsmall = 3), 
               ",%\n", sep = "")
  tex <- paste(tex,"\t/pandiso/fit/pearson/.initial=", 
               format(pandiso.fit.pearson, digits = 1, nsmall = 3), 
               ",%\n", sep = "")
  tex <- paste(tex,"\t/pandiso/fit/r/.initial=", 
               format(pandiso.fit.r, digits = 1, nsmall = 3), 
               ",%\n", sep = "")
  tex <- paste(tex,"\t/pandiso/overall/level/mean/.initial=", 
               format(pandiso.overall.level.mean, digits = 1, nsmall = 3), 
               ",%\n", sep = "")
  tex <- paste(tex,"\t/pandiso/overall/level/stdev/.initial=", 
               format(pandiso.overall.level.stdev, digits = 1, nsmall = 3), 
               ",%\n", sep = "")  
 tex <- paste(tex,"\t/pandiso/time/step/.initial=", 
               format(pandiso.time.step, digits = 1, nsmall = 0), 
               ",%\n", sep = "")  
  tex <- paste(tex, "}%", sep = "")
  writeLines(tex, fp)
  return(pandiso.update.preprint)
}
```

# Introduction

The logistic function is used to estimate the number 
of individuals infected by a virus in a time $t+1$
using the average isolation level in a population at a time $t$. 
Each time step is composed by a date range in days 
where the isolation level is supposed to take effect over the 
virus spread.

# Logistic function

```{r}
library(ggplot2)
library(latex2exp)
# Smooth the line plotted
require(splines)
# Differential equations solver
library(deSolve)
df.logistic <- function (t, y, parms) {
  list(parms["r"] * y * (1-y/parms["K"]))
}
t_final <- 295
times <- seq(from=1, to=t_final, by=1)
y_initial <- c(y=1)
parms <- c(r=0.04, K=350)
out <- ode(func=df.logistic, y=y_initial, 
           times=times, parms=parms)
# Normalize (standardize) the data

for (i in 1:2) {
  out[,i] <- out[,i] / max(out[,i])
}
# Create the data frame from logistic output
df <- data.frame(t=out[,1], y=out[,2])
# Plot
xy <- data.frame(predict(interpSpline(df$t, df$y)))
p <- ggplot(xy, aes(x, y)) + geom_line() +
     labs(title = "Logistic function", 
          x = "t", y = "n\n") +
    geom_label(
      aes(label="midpoint", 
          x=.57,
          y=.5,
          label.size = 0.35),
      color = "black",
      label.size = NA
  ) +
  annotate("point", x = .5, y = .5, colour = "black") +
  theme_light()
p

pandiso.write.plot("logistic", p)
pandiso.logistic.plot <- p
rm(df, df.logistic, i, out, p, parms, times, t_final, xy, y_initial)
```
# Stage 0 - Data Organization

The data are processed in periods of time, we use days as 
unit for time and avoid the use of fractional values to 
simplify the code and calculations. Another justification 
for the discrete values for time is that we are handling 
approximations for the conditions studied.

The value of `pandiso.time.step` (see [Processing])
was adopted after a set of tests 
were performed to check which value causes 
 a better correlation in the curves 
 for the model and estimated data. 
 This high correlation means that 
 the isolation level in that time step 
 affects the number of cases in the 
 next time step.


## COVID-19 cases

The COVID-19 cases are gathered from 
["São Paulo Plan"](https://www.saopaulo.sp.gov.br/planosp/) 
 organized by the government of São Paulo State. Brazil 
 to concentrate efforts to handle the virus spread in the 
 state. The file containing the cases, and other data, 
 is downloaded from 
 [Github repository](https://github.com/seade-R/dados-covid-sp)
 for the initiative.

```{r}
fn <- "dados_covid_sp.csv"
# Download the data from original source
pandiso.cases.file.path <- pandiso.file.path(fn);
fp <- pandiso.cases.file.path
if (file.exists(fp) == FALSE) {
  download.file(paste("https://raw.githubusercontent.com/seade-R/dados-covid-sp/master/data/", fn, sep = ""), fp)
}
# Read CSV file organizing the data according to columns
df <- read.csv(fp, header = TRUE, sep = ";");
# Sum the cases for all cities by date
dfc <- aggregate(casos_novos~datahora, FUN=sum, data=df)
# Rename the data frame columns
names(dfc)[names(dfc) == "datahora"] <- "date"
names(dfc)[names(dfc) == "casos_novos"] <- "cases"
# Convert date string to date Class
dfc$date <- as.Date(dfc$date)
rm(fp, fn)
```

## Population isolation level

The isolation level for all cities in the São Paulo State are 
stored in an Excel file downloaded from 
[``São Paulo Government Isolation Monitoring'' site](https://www.saopaulo.sp.gov.br/coronavirus/isolamento/).

The file must be downloaded manually after clicking in the "DADOS" button, 
then click "Baixar" icon, choose "Tabela de referência cruzada", "Excel" format
  and click "Baixar" button. 
 We choose the Excel format because its content could be parsed with 
 reliability. The isolation dates are synchronized cases data, only the 
 format is different ("DD/MM/YY"), but this is fixed by changing it to
 "YYYY-MM-DD".

```{r}
library(readxl)
fn <- "Dados.xlsx"
pandiso.isolation.file.path <- pandiso.file.path(fn)
fp <- pandiso.isolation.file.path
df <- read_excel(fp)
# The isolation level data start at 5th column and the
# first row is the date, the rest are isolation level 
# values.
shift <- 4 # 5th column because indices in R start at 1
dates <- vector("character", ncol(df) - shift)
values <- vector("numeric", ncol(df) - shift)
for (j in (shift+1):ncol(df)) {
  # process dates
  tmp <- toString(df[1,j])
  tmp <- unlist(strsplit(tmp, "/"))
  # convert "DD/MM/YY" to "YYYY-MM-DD"
  tmp <- paste(paste("20", tmp[[3]], sep=""), tmp[[2]], tmp[[1]], sep="-")
  dates[j-shift] <- as.character(tmp)
  # process isolation level values
  tmps <- as.numeric(unlist(as.list(df[2:nrow(df),j])))
  # mark non-empty cells, in some cells the value is missing
  good <- complete.cases(tmps)
  values[j-shift] <- mean(tmps[good])
}
dfl <- data.frame(date=as.Date(dates), level=values)
rm(fn, fp, good, j, shift, tmp, tmps, values)
```

## Processing {#processing}

The time step in days which the data points are grouped 
must be assigned to `pandiso.time.step` variable.

The sum of cases in a time step (period) are accumulated 
and the last date of the period is associated with the
cumulative value. The same reasoning for isolation level, 
with the exception that the levels are averaged in the period.

The isolation level data frame `dfl` is used to calculate
the number of steps `pandiso.count.time.steps` 
because there is a delay in the data update of COVID-19 cases 
and isolation levels. For these reason, the number of steps is based 
on the variable that has the chance to have less values.

```{r}
# Time step in days to be used along the R code.
pandiso.time.step <- 5  # days

# Cases are accumulated along the time
pandiso.cases.are.accumulated <- TRUE
is_cumul <- pandiso.cases.are.accumulated
# Number of elements in the data frame
pandiso.count.time.steps <- floor(length(dfl[,1]) /  pandiso.time.step)
n <- pandiso.count.time.steps
cases_dt <- vector("numeric", n)
levels_dt <- vector("numeric", n)
dates_dt <- vector("character", n)
# Find the intersection of dates to avoid mismatch.
dates <- intersect(as.character(dfc[,"date"]), as.character(dfl[,"date"]))
for (i in 1:n) {
  # Time step [inf, sup]
  # time lower bound
  inf <- pandiso.time.step * (i-1) + 1
  # time upper bound
  sup <- pandiso.time.step * i
  
  # Date interval is marked by the upper bound
  dates_dt[i] <- dates[sup]
  # The levels are averaged
  levels_dt[i] <- mean(dfl[dfl$date >= dates[inf] & dfl$date <= dates[sup],]$level)
  
  if (is_cumul == TRUE) {
    inf <- 1
  }
  # The cases are summed since from the first case if IS.CUMULATIVE is TRUE
  cases_dt[i] <-  sum(dfc[dfc$date >= dates[inf] & dfc$date <= dates[sup],]$cases)
}
dfdt = data.frame(date=dates_dt, empirical=cases_dt, level=levels_dt)
# Add time steps to data frame
times <- seq(from=1, to=length(dfdt$level), by=1)
dfdt$time <- times
rm(times)
# Total number of dates, remembering the dates considered
# as marks are in steps of pandiso.time.step value.
pandiso.count.total.dates <- sup

# Clean up some variables not needed anymore
rm(cases_dt, dates, dates_dt, i, inf, is_cumul, levels_dt, n, sup)
```

# Stage 1 - Fitting

The logistic function in the exponential form is used to fit the 
observed number of COVID-19 cases. The parameters from fitting 
are used in the estimation phase:

\begin{equation}
\tag{1}
f(t)= {K \over 1 + ({ K-m \over m }) e^{−rt}}
\end{equation}


\noindent where:

$t$ - a list of values representing the time steps;

$m$ - the sigmoid's midpoint;

$K$ - the maximum value for f(t);

$r$ - the the logistic growth rate.


```{r}
library(ggplot2)
library(minpack.lm)
temp <- data.frame(y = dfdt$empirical, x = dfdt$time)
logistic.model <- nlsLM(y ~ (K/ (1 + ((K-m)/m)*exp(- r * x))), 
                        data = temp, 
                        start = list(K = 1, m=1, r = 0.1))
summary(logistic.model)
fit <- predict(logistic.model, list(x = temp$x))
dfdt$fit <- fit
rm(fit, temp)

# Plot
p <- ggplot(dfdt) + geom_point(aes(time, empirical)) +
     geom_line(aes(time, fit), size = 1, col = "gray50") +
     labs(title = paste("Fitting of empirical data using", pandiso.time.step, "days as time step"),
          x = "time", y= "accumulated cases") +
    scale_x_continuous(breaks=seq(0, max(dfdt$time), 20)) +
    theme_light()
p
pandiso.write.plot("fit", p)
pandiso.fit.plot <- p

# Test the correlation of the empirical data and the model
c <- cor.test(dfdt$empirical, dfdt$fit, method=c("pearson"))
c
pandiso.fit.pearson <- c$estimate
rm(c, p)
```
# Stage 2 - Estimating

The estimation is performed after the calculation of $\lambda$ using the equation 2:

\begin{equation}
\tag{2}
 \lambda = r_{fit}\, \overline{i\,},
 \end{equation}
 
\noindent where: 

$r_{fit}$ - the logistic growth rate obtained from 
fitting;

$\overline{i\,}$ - the mean of all isolation 
level values.

The $\lambda$ is used to estimate the number of cases 
$N(t)$ using the logistic function in the exponential form, 
substituting the parameters by the fitted ones with the exception 
of the growth rate from the previous time step that now 
is considered as a dependent variable correlated with the 
isolation level of that time step and it's calculated by

\begin{equation}
\tag{3}
r(t-1) = {\lambda\over i(t-1)},
\end{equation}

and the logistic function calculates the current number of cases based 
on the previous time step isolation level using:

\begin{equation}
\tag{4}
N(t)= {K \over 1 + ({ K-N_m \over N_m }) e^{−r(t-1)\, (t)}}
\end{equation}

\noindent where:

$K$ - maximum value reachable by $N$;

$N_m$ - number of cases in the curve's midpoint;

$r(t-1)$ - growth rate from the previous period;

$t$ - time and $t\in \{2..t_{final}\}$.


```{r}
library(ggplot2)
library(patchwork)
library(reshape2)
# Estimation of cases using fitted parameters and 
# the mean of isolation level at each time step.
exp.logistic <- function(t, r_t, K, m) {
    y <- K / (1 + ((K-m)/m)*exp(-r_t * t))
    y
}

# Calculate the constant alpha
pandiso.fit.r <- coef(logistic.model)["r"]
pandiso.overall.level.mean <- mean(dfdt$level)
pandiso.overall.level.stdev <- sd(dfdt$level)
pandiso.lambda <- pandiso.fit.r * pandiso.overall.level.mean

pandiso.fit.K <- coef(logistic.model)["K"]
pandiso.fit.m <- coef(logistic.model)["m"]
# Estimate the number of cases N(t+dt)
estimated = vector("numeric", pandiso.count.time.steps)
# Estimate the first case manually, but not the rest.
estimated[1] = 1
for (i in 2:pandiso.count.time.steps) {
  r_t <- pandiso.lambda/dfdt$level[i]
  # This is t+dt compared with empirical time
  estimated[i] <- exp.logistic(i, r_t, pandiso.fit.K, pandiso.fit.m)
}
dfdt$estimated <- estimated
rm(estimated)

# Subplot in 2 rows, same x
## Subplot 1 - time x empirical+estimated
### Melt the desired data to plot
dfm <- melt(data.frame(time = dfdt$time, empirical = dfdt$empirical, 
                       estimated = dfdt$estimated), id = "time")
p1 <- ggplot(data = dfm, aes(x = time, y = value, color = variable)) + 
      geom_point(pch = 19, size = 1) +
      scale_color_manual(labels = unique(dfm$variable), values = c("black", "grey60")) + 
      labs(x = "", y = "accumulated cases", color = "", tag = "a)") +
      theme(axis.title.x = element_blank(), axis.text.x = element_blank(),
            legend.position = c(0.1, 0.675),  
            legend.background = element_rect(fill = "white", color = "black"),
            legend.title=element_blank()) +
      scale_x_continuous(breaks=seq(0, max(dfdt$time), 20)) +
      theme_light()

## Subplot 2 - time x mean isolation level
p2 <- ggplot(dfdt, aes(time, level)) +
      geom_point(pch = 19, size = 1.125,  col = "gray40") +
      labs(x = "time", y = "mean isolation level", tag = "b)") + 
      scale_x_continuous(breaks=seq(0, max(dfdt$time), 20)) +
      theme_light()
     
pandiso.estimation.plot <- (p1/p2)
pandiso.estimation.plot

pandiso.write.plot("estimation", pandiso.estimation.plot)

# Test the correlation of the empirical and estimated data.
c <- cor.test(dfdt$empirical, dfdt$estimated, method=c("pearson"))
c
pandiso.estimation.pearson <- c$estimate

pandiso.date.first <- dfdt[1, "date"]
pandiso.date.last <- dfdt[length(dfdt$date), "date"]
rm(c, i, r_t)

# Finish writing the values of some values to TeX variables 
# to be used in the preprint.
pandiso.write.TeX_macros()
```
